{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract donation folder\n",
    "#pyspark.options(\"RecursiveFileLookup\",\"True\").csv(\"Path to folder\")\n",
    "# precision = tp/(tp+fp)\n",
    "# recall = tp/(tp+fn)\n",
    "# f1 score = 2*precision*recall/(prec + recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Develop a PySpark script to clean and preprocess data before performing entity resolution.\n",
    "Include steps like tokenization and normalization.\n",
    "\n",
    "2) Implement a PySpark program that computes similarity scores between records using a\n",
    "chosen similarity metric.\n",
    "\n",
    "3)\n",
    "Implement a PySpark program to evaluate the precision, recall, and F1-score of an entity\n",
    "resolution model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import os\n",
    "import sys\n",
    "from pyspark import SparkContext\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lplab/anaconda3/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"16g\").appName('chapter_2').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "|  _c0|  _c1|              _c2|         _c3|         _c4|         _c5|    _c6|   _c7|   _c8|   _c9|   _c10|    _c11|\n",
      "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "| id_1| id_2|     cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|\n",
      "|37291|53113|0.833333333333333|           ?|           1|           ?|      1|     1|     1|     1|      0|    TRUE|\n",
      "|39086|47614|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|70031|70237|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|84795|97439|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|36950|42116|                1|           ?|           1|           1|      1|     1|     1|     1|      1|    TRUE|\n",
      "|42413|48491|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|25965|64753|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|49451|90407|                1|           ?|           1|           ?|      1|     1|     1|     1|      0|    TRUE|\n",
      "|39932|40902|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|46626|47940|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|48948|98379|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "| 4767| 4826|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|45463|69659|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|11367|13169|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|10782|89636|                1|           ?|           1|           ?|      1|     0|     1|     1|      1|    TRUE|\n",
      "|26206|39147|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|16662|27083|                1|           1|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|18823|30204|                1|           1|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|38545|85418|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prev=spark.read.options(recursiveFileLookup=\"True\").csv(\"/home/lplab/Desktop/BDAL/BDAL/WEEK3/data/block_1.csv\")\n",
    "prev.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = spark.read.option(\"header\", \"true\").option(\"nullValue\", \"?\").\\\n",
    "option(\"inferSchema\", \"true\").csv(\"data/block_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_1: integer (nullable = true)\n",
      " |-- id_2: integer (nullable = true)\n",
      " |-- cmp_fname_c1: double (nullable = true)\n",
      " |-- cmp_fname_c2: double (nullable = true)\n",
      " |-- cmp_lname_c1: double (nullable = true)\n",
      " |-- cmp_lname_c2: double (nullable = true)\n",
      " |-- cmp_sex: integer (nullable = true)\n",
      " |-- cmp_bd: integer (nullable = true)\n",
      " |-- cmp_bm: integer (nullable = true)\n",
      " |-- cmp_by: integer (nullable = true)\n",
      " |-- cmp_plz: integer (nullable = true)\n",
      " |-- is_match: boolean (nullable = true)\n",
      "\n",
      "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "| id_1| id_2|     cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|\n",
      "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "|37291|53113|0.833333333333333|        null|         1.0|        null|      1|     1|     1|     1|      0|    true|\n",
      "|39086|47614|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|70031|70237|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|84795|97439|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|36950|42116|              1.0|        null|         1.0|         1.0|      1|     1|     1|     1|      1|    true|\n",
      "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsed.printSchema()\n",
    "parsed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "574913"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id_1: int, id_2: int, cmp_fname_c1: double, cmp_fname_c2: double, cmp_lname_c1: double, cmp_lname_c2: double, cmp_sex: int, cmp_bd: int, cmp_bm: int, cmp_by: int, cmp_plz: int, is_match: boolean]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|is_match| count|\n",
      "+--------+------+\n",
      "|   false|572820|\n",
      "|    true|  2093|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "parsed.groupBy(\"is_match\").count().orderBy(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed.createOrReplaceTempView(\"linkage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|is_match|   cnt|\n",
      "+--------+------+\n",
      "|   false|572820|\n",
      "|    true|  2093|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT is_match, COUNT(*) cnt\n",
    "FROM linkage\n",
    "GROUP BY is_match\n",
    "ORDER BY cnt DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|      cmp_fname_c1|      cmp_fname_c2|\n",
      "+-------+------------------+------------------+\n",
      "|  count|            574811|             10325|\n",
      "|   mean|0.7127592938253411|0.8977586763518969|\n",
      "| stddev|0.3889286452463531|0.2742577520430532|\n",
      "|    min|               0.0|               0.0|\n",
      "|    max|               1.0|               1.0|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary = parsed.describe()\n",
    "summary.select(\"summary\", \"cmp_fname_c1\", \"cmp_fname_c2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = parsed.where(\"is_match = true\")\n",
    "match_summary = matches.describe()\n",
    "misses = parsed.filter(col(\"is_match\") == False)\n",
    "miss_summary = misses.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 12)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_p = summary.toPandas()\n",
    "summary_p.head()\n",
    "summary_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_p = summary_p.set_index('summary').transpose().reset_index()\n",
    "summary_p = summary_p.rename(columns={'index':'field'})\n",
    "summary_p = summary_p.rename_axis(None, axis=1)\n",
    "summary_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[field: string, count: string, mean: string, stddev: string, min: string, max: string]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaryT = spark.createDataFrame(summary_p)\n",
    "summaryT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- field: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      " |-- mean: string (nullable = true)\n",
      " |-- stddev: string (nullable = true)\n",
      " |-- min: string (nullable = true)\n",
      " |-- max: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summaryT.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- field: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      " |-- mean: string (nullable = true)\n",
      " |-- stddev: string (nullable = true)\n",
      " |-- min: string (nullable = true)\n",
      " |-- max: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "for c in summaryT.columns:\n",
    "    if c == 'field':\n",
    "        continue\n",
    "summaryT = summaryT.withColumn(c, summaryT[c].cast(DoubleType()))\n",
    "...\n",
    "summaryT.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import DoubleType\n",
    "def pivot_summary(desc):\n",
    "# convert to pandas dataframe\n",
    "    desc_p = desc.toPandas()\n",
    "# transpose\n",
    "    desc_p = desc_p.set_index('summary').transpose().reset_index()\n",
    "    desc_p = desc_p.rename(columns={'index':'field'})\n",
    "    desc_p = desc_p.rename_axis(None, axis=1)\n",
    "# convert to Spark dataframe\n",
    "    descT = spark.createDataFrame(desc_p)\n",
    "# convert metric columns to double from string\n",
    "    for c in descT.columns:\n",
    "        if c == 'field':\n",
    "            continue\n",
    "        else:\n",
    "            descT = descT.withColumn(c, descT[c].cast(DoubleType()))\n",
    "    return descT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_summaryT = pivot_summary(match_summary)\n",
    "miss_summaryT = pivot_summary(miss_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[field: string, total: double, delta: double]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_summaryT.createOrReplaceTempView(\"match_desc\")\n",
    "miss_summaryT.createOrReplaceTempView(\"miss_desc\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT a.field, a.count + b.count total, a.mean - b.mean delta\n",
    "FROM match_desc a INNER JOIN miss_desc b ON a.field = b.field\n",
    "WHERE a.field NOT IN (\"id_1\", \"id_2\")\n",
    "ORDER BY delta DESC, total DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cmp_lname_c1 + cmp_plz + cmp_by + cmp_bd + cmp_bm'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_features = [\"cmp_lname_c1\", \"cmp_plz\", \"cmp_by\", \"cmp_bd\", \"cmp_bm\"]\n",
    "...\n",
    "sum_expression = \" + \".join(good_features)\n",
    "...\n",
    "sum_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|score|is_match|\n",
      "+-----+--------+\n",
      "|  4.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  4.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  4.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "scored = parsed.fillna(0, subset=good_features).\\\n",
    "withColumn('score', expr(sum_expression)).\\\n",
    "select('score', 'is_match')\n",
    "...\n",
    "scored.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossTabs(scored: DataFrame, t: DoubleType) -> DataFrame:\n",
    "    return scored.selectExpr(f\"score >= {t} as above\", \"is_match\").\\\n",
    "        groupBy(\"above\").pivot(\"is_match\", (\"true\", \"false\")).\\\n",
    "        count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+\n",
      "|above|true| false|\n",
      "+-----+----+------+\n",
      "| true|2087|    66|\n",
      "|false|   6|572754|\n",
      "+-----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crossTabs(scored, 4.0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+\n",
      "|above|true| false|\n",
      "+-----+----+------+\n",
      "| true|2093| 59729|\n",
      "|false|null|513091|\n",
      "+-----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crossTabs(scored, 2.0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(above=True, true=2087, false=66), Row(above=False, true=6, false=572754)]\n"
     ]
    }
   ],
   "source": [
    "report=crossTabs(scored, 4.0).collect()\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP=report[0][1]\n",
    "FN=report[0][2]\n",
    "FP=report[1][1]\n",
    "TN=report[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.9971333014811276\n",
      "recall:  0.9693450998606595\n",
      "f1score:  0.9830428638718794\n"
     ]
    }
   ],
   "source": [
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "f1score = 2*precision*recall/(precision + recall)\n",
    "print(\"precision: \",precision)\n",
    "print(\"recall: \",recall)\n",
    "print(\"f1score: \",f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
